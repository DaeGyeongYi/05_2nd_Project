{
  "metadata": {
    "name": "강사",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "#### 현재데이터 : 9월13일 크롤링데이터 -\u003e 매일 크롤링하게 변경해야함\n#### 처리해야할 작업\n    1. 매일 크롤링한 csv 전체 다 가져오기\n    2. 최종테이블 저장 : 필요한컬럼- 법정동명(local), 학원명(academy_name),과목명(subject)\n\n#### 알고자 하는 내용\n    - 채용공고가 자주 올라오는 학원이름\n    \n#### 생각해봐야할 내용\n    - 어떻게 계속 spark로 df 만드는걸 반복적으로 수행할지\n    - 어떻게 계속 mysql에 저장할지\n    - 어떻게 크롤링한 데이터에서 count를 할지\n    - 중복되는 공고는 어떻게 처리해야할지?"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "#### 1. all_df : 크롤링한 csv전체 합침"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nall_df \u003d spark.read.csv(\u0027/Data/학원_Data/강사_채용정보/\u0027,header\u003d\u0027True\u0027)\nz.show(all_df)"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n#컬럼명정리\nfrom pyspark.sql.functions import col\ntut_df \u003d all_df.select(\n    col(\"academy_name\").alias(\"학원명\"),\n    col(\"local\").alias(\"법정동명\"),\n    col(\"subject\").alias(\"과목명\"))\nz.show(tut_df)"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ntut_df.count() #573+550 \u003d 1123"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ntut_df_1\u003dtut_df.rdd.zipWithIndex().toDF()\ntut_df\u003dtut_df_1.select(col(\"_1.*\"),col(\"_2\").alias(\"강사채용ID\"))\nz.show(tut_df)"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nz.show(tut_df)"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# 테이블저장\ntut_df.write.csv(\"hdfs:///강사.csv\",header\u003d\u0027True\u0027)"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ntut_df.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ntut_df.createOrReplaceTempView(\"all_tutor\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "#### 2. 시각화"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\nselect * from all_tutor\n"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\nselect `법정동명`, count(`학원명`) from all_tutor group by `법정동명` order by count(`학원명`) desc"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\nselect * from all_tutor where `학원명` \u003d\u003d \u0027황은영국어 2관\u0027\n"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\nselect count(distinct(academy_name)) from all_tutor -- 전체row수 1123, 중복 제거한 학원이름개수 661 \u003d 중복되는게 존재 "
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\nselect academy_name,count(academy_name) from all_tutor group by academy_name "
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\nselect * from all_tutor where academy_name \u003d \u0027황은영국어 2관\u0027 -- 중복되는 채용공고"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "#### 2. 최종테이블 저장 : 필요한컬럼- 법정동명(local), 학원명(academy_name),과목명(subject)\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.sql.functions import concat, col, lit\ndf_fin \u003d all_df.select(col(\u0027local\u0027).alias(\u0027법정동명\u0027),col(\u0027academy_name\u0027).alias(\u0027학원명\u0027),col(\u0027subject\u0027).alias(\u0027과목명\u0027))\ndf_fin.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_fin.createOrReplaceTempView(\"tutor_local_final\")"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\nselect * from tutor_local_final"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\nselect count(distinct(`법정동명`)) from tutor_local_final"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\nselect `법정동명`,count(`학원명`) as `강사채용 학원수` from tutor_local_final group by `법정동명` order by `강사채용 학원수` desc"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n"
    }
  ]
}