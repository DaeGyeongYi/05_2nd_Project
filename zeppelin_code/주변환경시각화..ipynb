{
  "metadata": {
    "name": "주변환경시각화",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nupso \u003d spark.read.csv(\u0027/Data/주변환경_Data/최종본_유흥시설목록.csv\u0027,header\u003dTrue)\n\nupso.createOrReplaceTempView(\u0027upso_obj\u0027)\n\n\nupso.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\n\n\nSELECT COUNT(\u0027사업장명\u0027) AS count, `주소` FROM upso_obj GROUP BY `주소` ORDER BY count DESC LIMIT 20;\n\n\n-- SELECT COUNT(DISTINCT(`법정동코드`)) FROM upso_obj"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.sql.functions import *\n\n\nsub \u003d spark.read.csv(\"/Data/주변환경_Data/최종본_전국지하철역목록.csv\",header\u003dTrue)\n\nsub \u003d sub.withColumn(\u0027법정동코드\u0027, (sub.법정동코드/100000).cast(\"int\"))\n\n\nsub \u003d sub.select(\n    col(\u0027역번호\u0027).alias(\u0027지하철역번호\u0027),\n    col(\u0027역사명\u0027).alias(\u0027지하철역사명\u0027),\n    col(\u0027주소\u0027),\n    col(\u0027노선명\u0027),\n    col(\u0027노선번호\u0027),\n    col(\u0027환승역구분\u0027),\n    col(\u0027환승노선개수\u0027),\n    col(\u0027환승노선번호\u0027),\n    col(\u0027환승노선명\u0027),\n    col(\u0027법정동코드\u0027),\n    )\n\n    \n\nsub.createOrReplaceTempView(\u0027sub_obj\u0027)\n\nsub.printSchema()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\nSELECT COUNT(\u0027지하철역사명\u0027) AS count,`주소` FROM sub_obj GROUP BY `주소` ORDER BY count DESC LIMIT 20;"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\nSELECT COUNT(`지하철역사명`) AS count ,`주소`  FROM sub_obj WHERE `환승역구분` \u003d\u003d \u0027환승역\u0027 GROUP BY `주소` ORDER BY count DESC LIMIT 20;"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ndf1 \u003d spark.read.csv(\"/버스정류장_for_DB_1.csv\",header\u003dTrue)\ndf2 \u003d spark.read.csv(\"/버스정류장_for_DB_2.csv\",header\u003dTrue)\n\n\n\nresult \u003d df1.union(df2)\n\n#result.show()\n\n\n\nresult.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\n\n\nSELECT COUNT(`버스정류장명`) AS count ,`주소`  FROM bus_obj GROUP BY `주소` ORDER BY count DESC LIMIT 20;\n"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": "%%sql\n"
    }
  ]
}