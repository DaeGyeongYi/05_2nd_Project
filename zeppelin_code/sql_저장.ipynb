{
  "metadata": {
    "name": "test_sql",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.sql.functions import col\n\n\nregion_code \u003d spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/지역.csv\")\n\n\nregion_code \u003d region_code.select(\n    col(\u0027법정동코드\u0027),\n    col(\u0027시도명\u0027),\n    col(\u0027법정동명\u0027)\n    )\n\nregion_code.show(50)\n\n\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nuser\u003d\"root\"\npassword\u003d\"1234\"\nurl\u003d\"jdbc:mysql://localhost:3306/Project\"\ndriver\u003d\"com.mysql.cj.jdbc.Driver\"\ndbtable\u003d\"지역\"\n\n\n\ntest_df \u003d spark.read.format(\"jdbc\").option(\"user\", user).option(\"password\", password)\\\n.option(\"url\", url).option(\"driver\", driver).option(\"dbtable\", dbtable).load()\n\n\ntest_df.show()\n\n#region_code.write.jdbc(url, dbtable, \"append\", properties\u003d{\"driver\": driver, \"user\": user, \"password\": password})\n\ntest_df.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.sql.functions import *\n\nuser\u003d\"root\"\npassword\u003d\"1234\"\nurl\u003d\"jdbc:mysql://localhost:3306/Project\"\ndriver\u003d\"com.mysql.cj.jdbc.Driver\"\ndbtable\u003d\"지하철\"\n\n\n\nsub \u003d spark.read.csv(\"/Data/주변환경_Data/최종본_전국지하철역목록.csv\",header\u003dTrue)\nsub \u003d sub.withColumn(\u0027법정동코드\u0027, (sub.법정동코드/100000).cast(\"int\"))\nsub \u003d sub.select(\n    col(\u0027_c0\u0027),\n    col(\u0027역번호\u0027),\n    col(\u0027역사명\u0027).alias(\u0027지하철역사명\u0027),\n    col(\u0027노선명\u0027),\n    col(\u0027노선번호\u0027),\n    col(\u0027환승역구분\u0027),\n    col(\u0027환승노선개수\u0027),\n    col(\u0027환승노선번호\u0027),\n    col(\u0027환승노선명\u0027),\n    col(\u0027법정동코드\u0027),\n    )\n\n\n\n\nsub \u003d sub.na.fill(\"-\")\n\n\nsub\u003dsub.dropDuplicates([\u0027지하철역사명\u0027,\u0027역번호\u0027,\u0027법정동코드\u0027]).sort(\u0027역번호\u0027)\n\n\nsub \u003d sub.select(\n    col(\u0027_c0\u0027).alias(\u0027지하철역번호\u0027),\n    col(\u0027지하철역사명\u0027),\n    col(\u0027노선명\u0027),\n    col(\u0027노선번호\u0027),\n    col(\u0027환승역구분\u0027),\n    col(\u0027환승노선개수\u0027),\n    col(\u0027환승노선번호\u0027),\n    col(\u0027환승노선명\u0027),\n    col(\u0027법정동코드\u0027),\n    )\n    \n    \n    \n\nsub.write.option(\"header\", \"true\").csv(\"hdfs:///지하철.csv\")\n\n\n#sub.write.jdbc(url, dbtable, \"append\", properties\u003d{\"driver\": driver, \"user\": user, \"password\": password})\n\n\n\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.sql.functions import *\n\nuser\u003d\"root\"\npassword\u003d\"1234\"\nurl\u003d\"jdbc:mysql://localhost:3306/Project\"\ndriver\u003d\"com.mysql.cj.jdbc.Driver\"\ndbtable\u003d\"버스정류장\"\n\ntest_df \u003d spark.read.format(\"jdbc\").option(\"user\", user).option(\"password\", password)\\\n.option(\"url\", url).option(\"driver\", driver).option(\"dbtable\", dbtable).load()\n\ndf1 \u003d spark.read.csv(\"/Data/주변환경_Data/final_in_spark/fin_bus_01.csv\")\ndf2 \u003d spark.read.csv(\"/Data/주변환경_Data/final_in_spark/fin_bus_02.csv\")\n\n\n\nresult \u003d df1.union(df2)\n\nfin\u003dresult.rdd.zipWithIndex().toDF()\nfinal\u003dfin.select(col(\"_1.*\"),col(\"_2\").alias(\u0027increasing_id\u0027))\n\n\n\nfinal \u003d final.select(\n    col(\u0027increasing_id\u0027).alias(\u0027버스정류장ID\u0027),\n    col(\u0027_c0\u0027).alias(\u0027버스정류장명\u0027),\n    col(\u0027_c1\u0027).alias(\u0027법정동코드\u0027)\n    )\n    \n\n#final.show()\n\nfinal.write.option(\"header\", \"true\").csv(\"hdfs:///버스정류장.csv\")\n#final.write.jdbc(url, dbtable, \"append\", properties\u003d{\"driver\": driver, \"user\": user, \"password\": password})"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nuser\u003d\"root\"\npassword\u003d\"1234\"\nurl\u003d\"jdbc:mysql://localhost:3306/Project\"\ndriver\u003d\"com.mysql.cj.jdbc.Driver\"\ndbtable\u003d\"유흥업소\"\n\ntest_df \u003d spark.read.format(\"jdbc\").option(\"user\", user).option(\"password\", password)\\\n.option(\"url\", url).option(\"driver\", driver).option(\"dbtable\", dbtable).load()\n\nupso \u003d spark.read.csv(\u0027/Data/주변환경_Data/최종본_유흥시설목록.csv\u0027,header\u003dTrue)\n\n\nupso \u003d upso.withColumn(\u0027법정동코드\u0027, (upso.법정동코드/100000).cast(\"int\"))\n\ntest_df.show()\n\n\nupso \u003d upso.select(\n    col(\u0027_c0\u0027).alias(\u0027유흥업소ID\u0027),\n    col(\u0027법정동코드\u0027),\n    col(\u0027사업장명\u0027),\n    col(\u0027업태구분명\u0027).alias(\u0027구분명\u0027))\n    \nupso.write.option(\"header\", \"true\").csv(\"hdfs:///유흥업소.csv\")\n#upso.write.jdbc(url, dbtable, \"append\", properties\u003d{\"driver\": driver, \"user\": user, \"password\": password})"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.sql.functions import col\nuser\u003d\"root\"\npassword\u003d\"1234\"\nurl\u003d\"jdbc:mysql://localhost:3306/Project\"\ndriver\u003d\"com.mysql.cj.jdbc.Driver\"\ndbtable\u003d\"학군\"\n\n\nschool_region \u003d spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/학군.csv\")\n\n#school_region\u003dschool_region(\u0027중학교학업중단자수\u0027).alias(\u0027중학교_학업중단자수\u0027)\nschool_region \u003d school_region.select(\n    col(\u0027_c0\u0027).alias(\u0027학군ID\u0027),\n    col(\u0027법정동코드\u0027),\n    col(\u0027중등교원총계\u0027),\n    col(\u0027중등학령인구\u0027),\n    col(\u0027중학교학업중단자수\u0027).alias(\u0027중학교 학업중단자수\u0027),\n    col(\u0027고등학교학업중단자수\u0027).alias(\u0027고등학교 학업중단자수\u0027),\n    col(\u0027비평준화여부\u0027)\n    )\n\nschool_region.write.jdbc(url, dbtable, \"append\", properties\u003d{\"driver\": driver, \"user\": user, \"password\": password})\nschool_region.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.sql.functions import col\nuser\u003d\"root\"\npassword\u003d\"1234\"\nurl\u003d\"jdbc:mysql://localhost:3306/Project\"\ndriver\u003d\"com.mysql.cj.jdbc.Driver\"\ndbtable\u003d\"유초등학교\"\n\nprimary \u003d spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/유초등학교.csv\")\n\nprimary \u003d primary.select(\n     col(\u0027_c0\u0027).alias(\u0027학교ID\u0027),\n    col(\u0027유초등학교명\u0027),\n    col(\u0027학교종류\u0027)\n)\n\n\n\nprimary.write.jdbc(url, dbtable, \"append\", properties\u003d{\"driver\": driver, \"user\": user, \"password\": password})\nprimary.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.sql.functions import col\nuser\u003d\"root\"\npassword\u003d\"1234\"\nurl\u003d\"jdbc:mysql://localhost:3306/Project\"\ndriver\u003d\"com.mysql.cj.jdbc.Driver\"\ndbtable\u003d\"교육청\"\n\neducation_center \u003d spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/교육청.csv\")\n\neducation_center \u003d education_center.select(\n    col(\u0027교육청코드\u0027),\n    col(\u0027교육청명\u0027),\n    col(\u0027시도명\u0027),\n    col(\u0027예산\u0027),\n)\n\n\n\neducation_center.write.jdbc(url, dbtable, \"append\", properties\u003d{\"driver\": driver, \"user\": user, \"password\": password})\neducation_center.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nfrom pyspark.sql.functions import col\nuser\u003d\"root\"\npassword\u003d\"1234\"\nurl\u003d\"jdbc:mysql://localhost:3306/Project\"\ndriver\u003d\"com.mysql.cj.jdbc.Driver\"\ndbtable\u003d\"중학교\"\n\nmiddle \u003d spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/중학교.csv\")\n\nmiddle \u003dmiddle.select(\n     col(\u0027_c0\u0027).alias(\u0027학교ID\u0027),\n    col(\u0027중학교명\u0027),\n    col(\u0027학교종류\u0027),\n    col(\u0027주소\u0027),\n    col(\u0027특목고진학자수\u0027)\n)\n\n\n\nmiddle.write.jdbc(url, dbtable, \"append\", properties\u003d{\"driver\": driver, \"user\": user, \"password\": password})\nmiddle.show(5)"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.sql.functions import col\nuser\u003d\"root\"\npassword\u003d\"1234\"\nurl\u003d\"jdbc:mysql://localhost:3306/Project\"\ndriver\u003d\"com.mysql.cj.jdbc.Driver\"\ndbtable\u003d\"고등학교\"\n\nhigh \u003d spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/고등학교.csv\")\n\nhigh \u003dhigh.select(\n    col(\u0027_c0\u0027).alias(\u0027학교ID\u0027),\n    col(\u0027고등학교명\u0027),\n    col(\u0027학교종류\u0027),\n    col(\u0027주소\u0027),\n    col(\u0027서울대합격자수\u0027)\n)\n\n\n\nhigh.write.jdbc(url, dbtable, \"append\", properties\u003d{\"driver\": driver, \"user\": user, \"password\": password})\nhigh.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\n\nSELECT * FROM subway WHERE `환승노선명` \u003d\u003d \u0027-\u0027 AND `환승노선번호` \u003d\u003d \u0027-\u0027\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": "%%sql\n"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.sql.functions import col\nuser\u003d\"root\"\npassword\u003d\"1234\"\nurl\u003d\"jdbc:mysql://localhost:3306/Project\"\ndriver\u003d\"com.mysql.cj.jdbc.Driver\"\ndbtable\u003d\"학원\"\n\n\naca_region \u003d spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/학원.csv\")\n\naca_region \u003d aca_region.select(\u0027*\u0027)    \n\naca_region.write.jdbc(url, dbtable, \"append\", properties\u003d{\"driver\": driver, \"user\": user, \"password\": password})\naca_region.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.sql.functions import col\nuser\u003d\"root\"\npassword\u003d\"1234\"\nurl\u003d\"jdbc:mysql://localhost:3306/Project\"\ndriver\u003d\"com.mysql.cj.jdbc.Driver\"\ndbtable\u003d\"강사\"\n\ntut_region \u003d spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/강사.csv\")\n\ntut_region \u003d tut_region.select(\u0027*\u0027)    \n\ntut_region.write.jdbc(url, dbtable, \"append\", properties\u003d{\"driver\": driver, \"user\": user, \"password\": password})\nz.show(tut_region)"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n"
    }
  ]
}